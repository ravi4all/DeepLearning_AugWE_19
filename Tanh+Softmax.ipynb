{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,target = make_moons(n_samples=400,noise=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63264076, 0.86643504])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X,model):\n",
    "    wh,bh,wout,bout = model['wh'],model['bh'],model['wout'],model['bout']\n",
    "    z1 = np.dot(X,wh) + bh\n",
    "    hidden = np.tanh(z1)\n",
    "    z2 = np.dot(hidden,wout) + bout\n",
    "    exp = np.exp(z2)\n",
    "    output = exp / np.sum(exp, keepdims=True, axis=1)\n",
    "    \n",
    "    pred = np.argmax(output)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X,model):\n",
    "    wh,bh,wout,bout = model['wh'],model['bh'],model['wout'],model['bout']\n",
    "    n = len(X)\n",
    "    z1 = np.dot(X,wh) + bh\n",
    "    hidden = np.tanh(z1)\n",
    "    z2 = np.dot(hidden,wout) + bout\n",
    "    exp = np.exp(z2)\n",
    "    output = exp / np.sum(exp, keepdims=True, axis=1)\n",
    "    \n",
    "    correct_log = -np.log(output[range(n),target])\n",
    "    data_loss = np.sum(correct_log)\n",
    "    \n",
    "    return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hiddenlayer_neurons):\n",
    "    wh,bh,wout,bout = init_weights(hiddenlayer_neurons)\n",
    "    n = len(data)\n",
    "    for i in range(epoch):\n",
    "        #Forward Propogation\n",
    "        z1 = np.dot(data,wh) + bh\n",
    "        hiddenLayer = np.tanh(z1)\n",
    "        z2 = np.dot(hiddenLayer,wout) + bout\n",
    "        exp = np.exp(z2)\n",
    "        output = exp / np.sum(exp, keepdims=True, axis=1)\n",
    "\n",
    "        #Backpropagation\n",
    "        d_output = output\n",
    "        d_output[range(n), target] -= 1\n",
    "        \n",
    "        d_hiddenlayer = d_output.dot(wout.T) * (1 - np.power(hiddenLayer,2))\n",
    "        \n",
    "        wout += hiddenLayer.T.dot(d_output) *(-lr)\n",
    "        bout += np.sum(d_output, axis=0,keepdims=True) *(-lr)\n",
    "        wh += data.T.dot(d_hiddenlayer) *(-lr)\n",
    "        bh += np.sum(d_hiddenlayer, axis=0,keepdims=True) *(-lr)\n",
    "        \n",
    "        model = {\"wh\":wh,\"bh\":bh,\"wout\":wout,\"bout\":bout}\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            l = loss(data,model)\n",
    "            print(\"Loss after {} iteration is {}\".format(i,l))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(hiddenlayer_neurons):\n",
    "\n",
    "    wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
    "    bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
    "    wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
    "    bout=np.random.uniform(size=(1,output_neurons))\n",
    "    \n",
    "    return wh,bh,wout,bout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=50000 #Setting training iterations\n",
    "lr=0.001 #Setting learning rate\n",
    "inputlayer_neurons = data.shape[1] #number of features in data set\n",
    "hiddenlayer_neurons = 3 #number of hidden layers neurons\n",
    "output_neurons = 2 #number of neurons at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 0 iteration is 246.91385315961122\n",
      "Loss after 100 iteration is 126.64139675817029\n",
      "Loss after 200 iteration is 124.34759462525095\n",
      "Loss after 300 iteration is 121.81190319938914\n",
      "Loss after 400 iteration is 119.34149018939728\n",
      "Loss after 500 iteration is 116.99668630419832\n",
      "Loss after 600 iteration is 113.53700547178242\n",
      "Loss after 700 iteration is 97.7704824285226\n",
      "Loss after 800 iteration is 66.88636630542109\n",
      "Loss after 900 iteration is 48.71865539369192\n",
      "Loss after 1000 iteration is 40.578844758652345\n",
      "Loss after 1100 iteration is 36.80615918566032\n",
      "Loss after 1200 iteration is 34.83511939895412\n",
      "Loss after 1300 iteration is 33.69044037336933\n",
      "Loss after 1400 iteration is 32.966399742030355\n",
      "Loss after 1500 iteration is 32.47444876520039\n",
      "Loss after 1600 iteration is 32.11875445302152\n",
      "Loss after 1700 iteration is 31.84721516025689\n",
      "Loss after 1800 iteration is 31.63006192123702\n",
      "Loss after 1900 iteration is 31.449649291070784\n",
      "Loss after 2000 iteration is 31.295216933070623\n",
      "Loss after 2100 iteration is 31.16003759915624\n",
      "Loss after 2200 iteration is 31.039791283065078\n",
      "Loss after 2300 iteration is 30.931608782655832\n",
      "Loss after 2400 iteration is 30.833500163933273\n",
      "Loss after 2500 iteration is 30.744013017844452\n",
      "Loss after 2600 iteration is 30.66203033432759\n",
      "Loss after 2700 iteration is 30.58665282781486\n",
      "Loss after 2800 iteration is 30.517131163575748\n",
      "Loss after 2900 iteration is 30.452826630275162\n",
      "Loss after 3000 iteration is 30.393187398941386\n",
      "Loss after 3100 iteration is 30.337733060042986\n",
      "Loss after 3200 iteration is 30.28604353887272\n",
      "Loss after 3300 iteration is 30.23775043932145\n",
      "Loss after 3400 iteration is 30.1925298936602\n",
      "Loss after 3500 iteration is 30.15009649047603\n",
      "Loss after 3600 iteration is 30.110198068299848\n",
      "Loss after 3700 iteration is 30.072611246772546\n",
      "Loss after 3800 iteration is 30.0371375975679\n",
      "Loss after 3900 iteration is 30.00360036931856\n",
      "Loss after 4000 iteration is 29.971841688557213\n",
      "Loss after 4100 iteration is 29.94172016649874\n",
      "Loss after 4200 iteration is 29.913108849903033\n",
      "Loss after 4300 iteration is 29.885893462758215\n",
      "Loss after 4400 iteration is 29.859970893542503\n",
      "Loss after 4500 iteration is 29.835247890008915\n",
      "Loss after 4600 iteration is 29.81163992965712\n",
      "Loss after 4700 iteration is 29.789070239317773\n",
      "Loss after 4800 iteration is 29.76746894166751\n",
      "Loss after 4900 iteration is 29.746772310128783\n",
      "Loss after 5000 iteration is 29.72692211661218\n",
      "Loss after 5100 iteration is 29.707865059035992\n",
      "Loss after 5200 iteration is 29.689552257604575\n",
      "Loss after 5300 iteration is 29.6719388105227\n",
      "Loss after 5400 iteration is 29.65498340123115\n",
      "Loss after 5500 iteration is 29.638647950422996\n",
      "Loss after 5600 iteration is 29.622897307082283\n",
      "Loss after 5700 iteration is 29.60769897361078\n",
      "Loss after 5800 iteration is 29.593022860803163\n",
      "Loss after 5900 iteration is 29.578841069017393\n",
      "Loss after 6000 iteration is 29.565127692384657\n",
      "Loss after 6100 iteration is 29.551858643325467\n",
      "Loss after 6200 iteration is 29.539011494999542\n",
      "Loss after 6300 iteration is 29.52656533962467\n",
      "Loss after 6400 iteration is 29.514500660864137\n",
      "Loss after 6500 iteration is 29.50279921870928\n",
      "Loss after 6600 iteration is 29.49144394547877\n",
      "Loss after 6700 iteration is 29.480418851725407\n",
      "Loss after 6800 iteration is 29.469708940986955\n",
      "Loss after 6900 iteration is 29.45930013244441\n",
      "Loss after 7000 iteration is 29.449179190660438\n",
      "Loss after 7100 iteration is 29.43933366166771\n",
      "Loss after 7200 iteration is 29.42975181475917\n",
      "Loss after 7300 iteration is 29.420422589406332\n",
      "Loss after 7400 iteration is 29.411335546795087\n",
      "Loss after 7500 iteration is 29.402480825525114\n",
      "Loss after 7600 iteration is 29.393849101068014\n",
      "Loss after 7700 iteration is 29.385431548622964\n",
      "Loss after 7800 iteration is 29.37721980904714\n",
      "Loss after 7900 iteration is 29.369205957571666\n",
      "Loss after 8000 iteration is 29.361382475044238\n",
      "Loss after 8100 iteration is 29.35374222146611\n",
      "Loss after 8200 iteration is 29.34627841161428\n",
      "Loss after 8300 iteration is 29.338984592561477\n",
      "Loss after 8400 iteration is 29.33185462292445\n",
      "Loss after 8500 iteration is 29.32488265368814\n",
      "Loss after 8600 iteration is 29.318063110468245\n",
      "Loss after 8700 iteration is 29.311390677087633\n",
      "Loss after 8800 iteration is 29.30486028035422\n",
      "Loss after 8900 iteration is 29.29846707593854\n",
      "Loss after 9000 iteration is 29.292206435258656\n",
      "Loss after 9100 iteration is 29.286073933288925\n",
      "Loss after 9200 iteration is 29.280065337216488\n",
      "Loss after 9300 iteration is 29.27417659587657\n",
      "Loss after 9400 iteration is 29.268403829903885\n",
      "Loss after 9500 iteration is 29.262743322542995\n",
      "Loss after 9600 iteration is 29.257191511065567\n",
      "Loss after 9700 iteration is 29.251744978747322\n",
      "Loss after 9800 iteration is 29.246400447361083\n",
      "Loss after 9900 iteration is 29.24115477014683\n",
      "Loss after 10000 iteration is 29.236004925222417\n",
      "Loss after 10100 iteration is 29.230948009402\n",
      "Loss after 10200 iteration is 29.22598123239212\n",
      "Loss after 10300 iteration is 29.22110191133767\n",
      "Loss after 10400 iteration is 29.216307465692417\n",
      "Loss after 10500 iteration is 29.211595412390928\n",
      "Loss after 10600 iteration is 29.2069633613005\n",
      "Loss after 10700 iteration is 29.202409010933515\n",
      "Loss after 10800 iteration is 29.19793014440221\n",
      "Loss after 10900 iteration is 29.193524625599366\n",
      "Loss after 11000 iteration is 29.189190395589556\n",
      "Loss after 11100 iteration is 29.184925469196855\n",
      "Loss after 11200 iteration is 29.180727931776385\n",
      "Loss after 11300 iteration is 29.176595936157206\n",
      "Loss after 11400 iteration is 29.172527699746034\n",
      "Loss after 11500 iteration is 29.168521501781193\n",
      "Loss after 11600 iteration is 29.164575680727545\n",
      "Loss after 11700 iteration is 29.16068863180363\n",
      "Loss after 11800 iteration is 29.156858804632932\n",
      "Loss after 11900 iteration is 29.153084701011615\n",
      "Loss after 12000 iteration is 29.149364872785977\n",
      "Loss after 12100 iteration is 29.14569791983304\n",
      "Loss after 12200 iteration is 29.142082488138122\n",
      "Loss after 12300 iteration is 29.138517267964147\n",
      "Loss after 12400 iteration is 29.135000992107017\n",
      "Loss after 12500 iteration is 29.1315324342326\n",
      "Loss after 12600 iteration is 29.128110407290556\n",
      "Loss after 12700 iteration is 29.124733762000798\n",
      "Loss after 12800 iteration is 29.12140138540881\n",
      "Loss after 12900 iteration is 29.118112199505774\n",
      "Loss after 13000 iteration is 29.11486515991051\n",
      "Loss after 13100 iteration is 29.111659254609567\n",
      "Loss after 13200 iteration is 29.10849350275265\n",
      "Loss after 13300 iteration is 29.10536695350048\n",
      "Loss after 13400 iteration is 29.102278684922528\n",
      "Loss after 13500 iteration is 29.099227802941808\n",
      "Loss after 13600 iteration is 29.096213440324757\n",
      "Loss after 13700 iteration is 29.093234755713624\n",
      "Loss after 13800 iteration is 29.090290932699624\n",
      "Loss after 13900 iteration is 29.08738117893452\n",
      "Loss after 14000 iteration is 29.084504725279057\n",
      "Loss after 14100 iteration is 29.081660824986372\n",
      "Loss after 14200 iteration is 29.078848752918788\n",
      "Loss after 14300 iteration is 29.076067804796253\n",
      "Loss after 14400 iteration is 29.073317296475324\n",
      "Loss after 14500 iteration is 29.07059656325671\n",
      "Loss after 14600 iteration is 29.06790495922078\n",
      "Loss after 14700 iteration is 29.06524185658907\n",
      "Loss after 14800 iteration is 29.06260664511113\n",
      "Loss after 14900 iteration is 29.059998731475275\n",
      "Loss after 15000 iteration is 29.05741753874235\n",
      "Loss after 15100 iteration is 29.054862505801353\n",
      "Loss after 15200 iteration is 29.05233308684612\n",
      "Loss after 15300 iteration is 29.049828750871953\n",
      "Loss after 15400 iteration is 29.047348981191522\n",
      "Loss after 15500 iteration is 29.044893274969063\n",
      "Loss after 15600 iteration is 29.042461142772197\n",
      "Loss after 15700 iteration is 29.040052108140586\n",
      "Loss after 15800 iteration is 29.03766570717054\n",
      "Loss after 15900 iteration is 29.035301488115337\n",
      "Loss after 16000 iteration is 29.03295901100008\n",
      "Loss after 16100 iteration is 29.030637847250865\n",
      "Loss after 16200 iteration is 29.0283375793375\n",
      "Loss after 16300 iteration is 29.026057800429175\n",
      "Loss after 16400 iteration is 29.023798114062764\n",
      "Loss after 16500 iteration is 29.021558133823074\n",
      "Loss after 16600 iteration is 29.01933748303442\n",
      "Loss after 16700 iteration is 29.01713579446347\n",
      "Loss after 16800 iteration is 29.01495271003255\n",
      "Loss after 16900 iteration is 29.012787880543108\n",
      "Loss after 17000 iteration is 29.010640965408985\n",
      "Loss after 17100 iteration is 29.00851163239902\n",
      "Loss after 17200 iteration is 29.00639955738869\n",
      "Loss after 17300 iteration is 29.004304424120324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 17400 iteration is 29.002225923971753\n",
      "Loss after 17500 iteration is 29.000163755732814\n",
      "Loss after 17600 iteration is 28.99811762538957\n",
      "Loss after 17700 iteration is 28.996087245915973\n",
      "Loss after 17800 iteration is 28.994072337072513\n",
      "Loss after 17900 iteration is 28.992072625211794\n",
      "Loss after 18000 iteration is 28.99008784309055\n",
      "Loss after 18100 iteration is 28.988117729688053\n",
      "Loss after 18200 iteration is 28.98616203003063\n",
      "Loss after 18300 iteration is 28.9842204950219\n",
      "Loss after 18400 iteration is 28.982292881278738\n",
      "Loss after 18500 iteration is 28.980378950972614\n",
      "Loss after 18600 iteration is 28.9784784716761\n",
      "Loss after 18700 iteration is 28.97659121621447\n",
      "Loss after 18800 iteration is 28.974716962522074\n",
      "Loss after 18900 iteration is 28.972855493503413\n",
      "Loss after 19000 iteration is 28.971006596898622\n",
      "Loss after 19100 iteration is 28.969170065153342\n",
      "Loss after 19200 iteration is 28.96734569529269\n",
      "Loss after 19300 iteration is 28.965533288799307\n",
      "Loss after 19400 iteration is 28.963732651495217\n",
      "Loss after 19500 iteration is 28.961943593427378\n",
      "Loss after 19600 iteration is 28.96016592875695\n",
      "Loss after 19700 iteration is 28.958399475651873\n",
      "Loss after 19800 iteration is 28.956644056182903\n",
      "Loss after 19900 iteration is 28.954899496222772\n",
      "Loss after 20000 iteration is 28.953165625348525\n",
      "Loss after 20100 iteration is 28.95144227674684\n",
      "Loss after 20200 iteration is 28.949729287122185\n",
      "Loss after 20300 iteration is 28.94802649660787\n",
      "Loss after 20400 iteration is 28.946333748679656\n",
      "Loss after 20500 iteration is 28.94465089007211\n",
      "Loss after 20600 iteration is 28.942977770697297\n",
      "Loss after 20700 iteration is 28.9413142435661\n",
      "Loss after 20800 iteration is 28.939660164711732\n",
      "Loss after 20900 iteration is 28.9380153931155\n",
      "Loss after 21000 iteration is 28.936379790634877\n",
      "Loss after 21100 iteration is 28.934753221933576\n",
      "Loss after 21200 iteration is 28.93313555441365\n",
      "Loss after 21300 iteration is 28.93152665814968\n",
      "Loss after 21400 iteration is 28.929926405824737\n",
      "Loss after 21500 iteration is 28.92833467266825\n",
      "Loss after 21600 iteration is 28.926751336395633\n",
      "Loss after 21700 iteration is 28.925176277149653\n",
      "Loss after 21800 iteration is 28.923609377443398\n",
      "Loss after 21900 iteration is 28.92205052210496\n",
      "Loss after 22000 iteration is 28.92049959822357\n",
      "Loss after 22100 iteration is 28.918956495097298\n",
      "Loss after 22200 iteration is 28.917421104182143\n",
      "Loss after 22300 iteration is 28.91589331904265\n",
      "Loss after 22400 iteration is 28.914373035303775\n",
      "Loss after 22500 iteration is 28.91286015060406\n",
      "Loss after 22600 iteration is 28.911354564550294\n",
      "Loss after 22700 iteration is 28.90985617867304\n",
      "Loss after 22800 iteration is 28.908364896383727\n",
      "Loss after 22900 iteration is 28.90688062293272\n",
      "Loss after 23000 iteration is 28.905403265368456\n",
      "Loss after 23100 iteration is 28.90393273249782\n",
      "Loss after 23200 iteration is 28.902468934847505\n",
      "Loss after 23300 iteration is 28.901011784626355\n",
      "Loss after 23400 iteration is 28.899561195688726\n",
      "Loss after 23500 iteration is 28.898117083498867\n",
      "Loss after 23600 iteration is 28.89667936509608\n",
      "Loss after 23700 iteration is 28.89524795906098\n",
      "Loss after 23800 iteration is 28.893822785482435\n",
      "Loss after 23900 iteration is 28.892403765925465\n",
      "Loss after 24000 iteration is 28.890990823399964\n",
      "Loss after 24100 iteration is 28.889583882330136\n",
      "Loss after 24200 iteration is 28.888182868524794\n",
      "Loss after 24300 iteration is 28.886787709148354\n",
      "Loss after 24400 iteration is 28.88539833269253\n",
      "Loss after 24500 iteration is 28.88401466894887\n",
      "Loss after 24600 iteration is 28.882636648981794\n",
      "Loss after 24700 iteration is 28.88126420510239\n",
      "Loss after 24800 iteration is 28.879897270842882\n",
      "Loss after 24900 iteration is 28.878535780931653\n",
      "Loss after 25000 iteration is 28.877179671268937\n",
      "Loss after 25100 iteration is 28.875828878903015\n",
      "Loss after 25200 iteration is 28.874483342007125\n",
      "Loss after 25300 iteration is 28.87314299985676\n",
      "Loss after 25400 iteration is 28.871807792807637\n",
      "Loss after 25500 iteration is 28.87047766227413\n",
      "Loss after 25600 iteration is 28.869152550708236\n",
      "Loss after 25700 iteration is 28.86783240157898\n",
      "Loss after 25800 iteration is 28.866517159352416\n",
      "Loss after 25900 iteration is 28.86520676947196\n",
      "Loss after 26000 iteration is 28.863901178339294\n",
      "Loss after 26100 iteration is 28.862600333295617\n",
      "Loss after 26200 iteration is 28.86130418260339\n",
      "Loss after 26300 iteration is 28.860012675428504\n",
      "Loss after 26400 iteration is 28.858725761822775\n",
      "Loss after 26500 iteration is 28.85744339270696\n",
      "Loss after 26600 iteration is 28.85616551985396\n",
      "Loss after 26700 iteration is 28.85489209587265\n",
      "Loss after 26800 iteration is 28.85362307419191\n",
      "Loss after 26900 iteration is 28.85235840904498\n",
      "Loss after 27000 iteration is 28.851098055454308\n",
      "Loss after 27100 iteration is 28.84984196921656\n",
      "Loss after 27200 iteration is 28.848590106888118\n",
      "Loss after 27300 iteration is 28.847342425770794\n",
      "Loss after 27400 iteration is 28.846098883897863\n",
      "Loss after 27500 iteration is 28.84485944002042\n",
      "Loss after 27600 iteration is 28.84362405359404\n",
      "Loss after 27700 iteration is 28.842392684765684\n",
      "Loss after 27800 iteration is 28.841165294360888\n",
      "Loss after 27900 iteration is 28.8399418438713\n",
      "Loss after 28000 iteration is 28.83872229544236\n",
      "Loss after 28100 iteration is 28.837506611861286\n",
      "Loss after 28200 iteration is 28.836294756545385\n",
      "Loss after 28300 iteration is 28.835086693530503\n",
      "Loss after 28400 iteration is 28.833882387459717\n",
      "Loss after 28500 iteration is 28.832681803572353\n",
      "Loss after 28600 iteration is 28.831484907693106\n",
      "Loss after 28700 iteration is 28.83029166622152\n",
      "Loss after 28800 iteration is 28.829102046121523\n",
      "Loss after 28900 iteration is 28.827916014911317\n",
      "Loss after 29000 iteration is 28.826733540653358\n",
      "Loss after 29100 iteration is 28.825554591944616\n",
      "Loss after 29200 iteration is 28.824379137907002\n",
      "Loss after 29300 iteration is 28.823207148177897\n",
      "Loss after 29400 iteration is 28.82203859290108\n",
      "Loss after 29500 iteration is 28.820873442717605\n",
      "Loss after 29600 iteration is 28.819711668756995\n",
      "Loss after 29700 iteration is 28.81855324262851\n",
      "Loss after 29800 iteration is 28.81739813641269\n",
      "Loss after 29900 iteration is 28.816246322653026\n",
      "Loss after 30000 iteration is 28.815097774347663\n",
      "Loss after 30100 iteration is 28.813952464941508\n",
      "Loss after 30200 iteration is 28.812810368318203\n",
      "Loss after 30300 iteration is 28.81167145879252\n",
      "Loss after 30400 iteration is 28.810535711102695\n",
      "Loss after 30500 iteration is 28.809403100402992\n",
      "Loss after 30600 iteration is 28.808273602256385\n",
      "Loss after 30700 iteration is 28.807147192627433\n",
      "Loss after 30800 iteration is 28.806023847875196\n",
      "Loss after 30900 iteration is 28.80490354474629\n",
      "Loss after 31000 iteration is 28.803786260368152\n",
      "Loss after 31100 iteration is 28.802671972242386\n",
      "Loss after 31200 iteration is 28.80156065823811\n",
      "Loss after 31300 iteration is 28.800452296585675\n",
      "Loss after 31400 iteration is 28.799346865870238\n",
      "Loss after 31500 iteration is 28.79824434502561\n",
      "Loss after 31600 iteration is 28.79714471332815\n",
      "Loss after 31700 iteration is 28.7960479503908\n",
      "Loss after 31800 iteration is 28.79495403615717\n",
      "Loss after 31900 iteration is 28.793862950895786\n",
      "Loss after 32000 iteration is 28.7927746751944\n",
      "Loss after 32100 iteration is 28.791689189954454\n",
      "Loss after 32200 iteration is 28.79060647638552\n",
      "Loss after 32300 iteration is 28.789526515999967\n",
      "Loss after 32400 iteration is 28.788449290607687\n",
      "Loss after 32500 iteration is 28.787374782310827\n",
      "Loss after 32600 iteration is 28.786302973498685\n",
      "Loss after 32700 iteration is 28.785233846842733\n",
      "Loss after 32800 iteration is 28.784167385291607\n",
      "Loss after 32900 iteration is 28.783103572066288\n",
      "Loss after 33000 iteration is 28.78204239065529\n",
      "Loss after 33100 iteration is 28.78098382480996\n",
      "Loss after 33200 iteration is 28.779927858539896\n",
      "Loss after 33300 iteration is 28.77887447610835\n",
      "Loss after 33400 iteration is 28.77782366202772\n",
      "Loss after 33500 iteration is 28.776775401055293\n",
      "Loss after 33600 iteration is 28.775729678188764\n",
      "Loss after 33700 iteration is 28.774686478662044\n",
      "Loss after 33800 iteration is 28.773645787941096\n",
      "Loss after 33900 iteration is 28.772607591719737\n",
      "Loss after 34000 iteration is 28.77157187591568\n",
      "Loss after 34100 iteration is 28.77053862666645\n",
      "Loss after 34200 iteration is 28.769507830325573\n",
      "Loss after 34300 iteration is 28.768479473458576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 34400 iteration is 28.76745354283931\n",
      "Loss after 34500 iteration is 28.76643002544612\n",
      "Loss after 34600 iteration is 28.765408908458216\n",
      "Loss after 34700 iteration is 28.764390179252068\n",
      "Loss after 34800 iteration is 28.763373825397757\n",
      "Loss after 34900 iteration is 28.76235983465554\n",
      "Loss after 35000 iteration is 28.7613481949724\n",
      "Loss after 35100 iteration is 28.760338894478593\n",
      "Loss after 35200 iteration is 28.759331921484325\n",
      "Loss after 35300 iteration is 28.758327264476485\n",
      "Loss after 35400 iteration is 28.75732491211536\n",
      "Loss after 35500 iteration is 28.75632485323149\n",
      "Loss after 35600 iteration is 28.755327076822475\n",
      "Loss after 35700 iteration is 28.75433157204992\n",
      "Loss after 35800 iteration is 28.75333832823636\n",
      "Loss after 35900 iteration is 28.752347334862286\n",
      "Loss after 36000 iteration is 28.751358581563196\n",
      "Loss after 36100 iteration is 28.75037205812665\n",
      "Loss after 36200 iteration is 28.749387754489483\n",
      "Loss after 36300 iteration is 28.74840566073487\n",
      "Loss after 36400 iteration is 28.747425767089688\n",
      "Loss after 36500 iteration is 28.746448063921676\n",
      "Loss after 36600 iteration is 28.745472541736824\n",
      "Loss after 36700 iteration is 28.74449919117669\n",
      "Loss after 36800 iteration is 28.743528003015776\n",
      "Loss after 36900 iteration is 28.74255896815901\n",
      "Loss after 37000 iteration is 28.74159207763917\n",
      "Loss after 37100 iteration is 28.74062732261442\n",
      "Loss after 37200 iteration is 28.739664694365892\n",
      "Loss after 37300 iteration is 28.738704184295223\n",
      "Loss after 37400 iteration is 28.737745783922193\n",
      "Loss after 37500 iteration is 28.73678948488244\n",
      "Loss after 37600 iteration is 28.73583527892508\n",
      "Loss after 37700 iteration is 28.734883157910502\n",
      "Loss after 37800 iteration is 28.733933113808106\n",
      "Loss after 37900 iteration is 28.732985138694147\n",
      "Loss after 38000 iteration is 28.73203922474951\n",
      "Loss after 38100 iteration is 28.731095364257662\n",
      "Loss after 38200 iteration is 28.7301535496025\n",
      "Loss after 38300 iteration is 28.72921377326631\n",
      "Loss after 38400 iteration is 28.728276027827754\n",
      "Loss after 38500 iteration is 28.72734030595985\n",
      "Loss after 38600 iteration is 28.726406600428035\n",
      "Loss after 38700 iteration is 28.725474904088188\n",
      "Loss after 38800 iteration is 28.724545209884795\n",
      "Loss after 38900 iteration is 28.723617510849014\n",
      "Loss after 39000 iteration is 28.722691800096865\n",
      "Loss after 39100 iteration is 28.721768070827434\n",
      "Loss after 39200 iteration is 28.720846316321023\n",
      "Loss after 39300 iteration is 28.7199265299375\n",
      "Loss after 39400 iteration is 28.719008705114476\n",
      "Loss after 39500 iteration is 28.718092835365677\n",
      "Loss after 39600 iteration is 28.717178914279213\n",
      "Loss after 39700 iteration is 28.716266935516007\n",
      "Loss after 39800 iteration is 28.715356892808135\n",
      "Loss after 39900 iteration is 28.71444877995723\n",
      "Loss after 40000 iteration is 28.713542590832965\n",
      "Loss after 40100 iteration is 28.71263831937148\n",
      "Loss after 40200 iteration is 28.71173595957388\n",
      "Loss after 40300 iteration is 28.71083550550477\n",
      "Loss after 40400 iteration is 28.70993695129078\n",
      "Loss after 40500 iteration is 28.70904029111916\n",
      "Loss after 40600 iteration is 28.70814551923629\n",
      "Loss after 40700 iteration is 28.707252629946417\n",
      "Loss after 40800 iteration is 28.70636161761021\n",
      "Loss after 40900 iteration is 28.705472476643422\n",
      "Loss after 41000 iteration is 28.704585201515656\n",
      "Loss after 41100 iteration is 28.703699786748977\n",
      "Loss after 41200 iteration is 28.702816226916717\n",
      "Loss after 41300 iteration is 28.701934516642197\n",
      "Loss after 41400 iteration is 28.70105465059752\n",
      "Loss after 41500 iteration is 28.700176623502387\n",
      "Loss after 41600 iteration is 28.699300430122854\n",
      "Loss after 41700 iteration is 28.698426065270276\n",
      "Loss after 41800 iteration is 28.697553523800117\n",
      "Loss after 41900 iteration is 28.696682800610816\n",
      "Loss after 42000 iteration is 28.695813890642743\n",
      "Loss after 42100 iteration is 28.69494678887712\n",
      "Loss after 42200 iteration is 28.69408149033496\n",
      "Loss after 42300 iteration is 28.69321799007601\n",
      "Loss after 42400 iteration is 28.69235628319781\n",
      "Loss after 42500 iteration is 28.691496364834663\n",
      "Loss after 42600 iteration is 28.690638230156644\n",
      "Loss after 42700 iteration is 28.689781874368688\n",
      "Loss after 42800 iteration is 28.688927292709657\n",
      "Loss after 42900 iteration is 28.688074480451363\n",
      "Loss after 43000 iteration is 28.68722343289781\n",
      "Loss after 43100 iteration is 28.68637414538414\n",
      "Loss after 43200 iteration is 28.68552661327596\n",
      "Loss after 43300 iteration is 28.68468083196835\n",
      "Loss after 43400 iteration is 28.683836796885146\n",
      "Loss after 43500 iteration is 28.682994503478053\n",
      "Loss after 43600 iteration is 28.682153947225963\n",
      "Loss after 43700 iteration is 28.681315123634054\n",
      "Loss after 43800 iteration is 28.680478028233164\n",
      "Loss after 43900 iteration is 28.67964265657901\n",
      "Loss after 44000 iteration is 28.67880900425139\n",
      "Loss after 44100 iteration is 28.67797706685362\n",
      "Loss after 44200 iteration is 28.677146840011773\n",
      "Loss after 44300 iteration is 28.676318319373973\n",
      "Loss after 44400 iteration is 28.6754915006098\n",
      "Loss after 44500 iteration is 28.674666379409693\n",
      "Loss after 44600 iteration is 28.67384295148417\n",
      "Loss after 44700 iteration is 28.673021212563388\n",
      "Loss after 44800 iteration is 28.67220115839646\n",
      "Loss after 44900 iteration is 28.671382784750886\n",
      "Loss after 45000 iteration is 28.670566087412023\n",
      "Loss after 45100 iteration is 28.66975106218248\n",
      "Loss after 45200 iteration is 28.6689377048816\n",
      "Loss after 45300 iteration is 28.668126011345016\n",
      "Loss after 45400 iteration is 28.667315977424035\n",
      "Loss after 45500 iteration is 28.666507598985163\n",
      "Loss after 45600 iteration is 28.66570087190972\n",
      "Loss after 45700 iteration is 28.664895792093223\n",
      "Loss after 45800 iteration is 28.66409235544505\n",
      "Loss after 45900 iteration is 28.66329055788795\n",
      "Loss after 46000 iteration is 28.662490395357604\n",
      "Loss after 46100 iteration is 28.661691863802265\n",
      "Loss after 46200 iteration is 28.660894959182265\n",
      "Loss after 46300 iteration is 28.660099677469695\n",
      "Loss after 46400 iteration is 28.659306014647985\n",
      "Loss after 46500 iteration is 28.658513966711563\n",
      "Loss after 46600 iteration is 28.657723529665475\n",
      "Loss after 46700 iteration is 28.65693469952504\n",
      "Loss after 46800 iteration is 28.656147472315542\n",
      "Loss after 46900 iteration is 28.655361844071855\n",
      "Loss after 47000 iteration is 28.65457781083817\n",
      "Loss after 47100 iteration is 28.65379536866771\n",
      "Loss after 47200 iteration is 28.65301451362237\n",
      "Loss after 47300 iteration is 28.652235241772487\n",
      "Loss after 47400 iteration is 28.65145754919655\n",
      "Loss after 47500 iteration is 28.65068143198097\n",
      "Loss after 47600 iteration is 28.64990688621976\n",
      "Loss after 47700 iteration is 28.64913390801434\n",
      "Loss after 47800 iteration is 28.64836249347331\n",
      "Loss after 47900 iteration is 28.647592638712204\n",
      "Loss after 48000 iteration is 28.64682433985328\n",
      "Loss after 48100 iteration is 28.646057593025297\n",
      "Loss after 48200 iteration is 28.645292394363338\n",
      "Loss after 48300 iteration is 28.644528740008653\n",
      "Loss after 48400 iteration is 28.643766626108388\n",
      "Loss after 48500 iteration is 28.643006048815483\n",
      "Loss after 48600 iteration is 28.6422470042885\n",
      "Loss after 48700 iteration is 28.641489488691448\n",
      "Loss after 48800 iteration is 28.640733498193622\n",
      "Loss after 48900 iteration is 28.63997902896949\n",
      "Loss after 49000 iteration is 28.639226077198536\n",
      "Loss after 49100 iteration is 28.63847463906518\n",
      "Loss after 49200 iteration is 28.637724710758558\n",
      "Loss after 49300 iteration is 28.636976288472543\n",
      "Loss after 49400 iteration is 28.636229368405488\n",
      "Loss after 49500 iteration is 28.63548394676025\n",
      "Loss after 49600 iteration is 28.63474001974404\n",
      "Loss after 49700 iteration is 28.633997583568355\n",
      "Loss after 49800 iteration is 28.633256634448863\n",
      "Loss after 49900 iteration is 28.632517168605347\n"
     ]
    }
   ],
   "source": [
    "model = build_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
